{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DoodleClassifierCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev64V3F36Bvm"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random as rd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM4U4CzQbNJ0",
        "outputId": "46957bbe-589a-47c8-df4c-de1fd2cdd988"
      },
      "source": [
        "#upload the doodle dataset zip file on your drive to use\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDt9bBgw6F7d"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjlCnu6bAOSz"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zYu9NT26x5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1c7dce-f9f4-47ac-9436-6c5a1f4b1b94"
      },
      "source": [
        "!unrar e '/content/drive/MyDrive/doodle/Doodle dataset.rar' #unrar the doodle dataset from your drive"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/doodle/Doodle dataset.rar\n",
            "\n",
            "Extracting  full_numpy_bitmap_airplane.npy                               \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_ant.npy                                    \b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_banana.npy                                 \b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_baseball.npy                               \b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_bird.npy                                   \b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_bucket.npy                                 \b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_butterfly.npy                              \b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_cat.npy                                    \b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_coffee cup.npy                             \b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_dolphin.npy                                \b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_donut.npy                                  \b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_duck.npy                                   \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_fish.npy                                   \b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_leaf.npy                                   \b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_mountain.npy                               \b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_pencil.npy                                 \b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_smiley face.npy                            \b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_snake.npy                                  \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_umbrella.npy                               \b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b\b  OK \n",
            "Extracting  full_numpy_bitmap_wine bottle.npy                            \b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGZbce-N8z7U",
        "outputId": "890e9c48-179a-4ed1-e1ae-54c9f853df56"
      },
      "source": [
        "classes = [\"airplane\", \"ant\", \"banana\", \"baseball\", \"bird\", \"bucket\", \"butterfly\", \"cat\", \"coffee cup\",\n",
        "           \"dolphin\", \"donut\", \"duck\", \"fish\", \"leaf\", \"mountain\", \"pencil\", \"smiley face\", \"snake\", \"umbrella\", \"wine bottle\"]\n",
        "print(len(classes))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov9F2JME1M2Q"
      },
      "source": [
        "Ap = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_airplane.npy\"))\n",
        "print(Ap.shape)\n",
        "l1=np.full((151623,1),0)\n",
        "ant = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_ant.npy\"))\n",
        "l2=np.full((124612,1),1)\n",
        "print(ant.shape)\n",
        "bn = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_banana.npy\"))\n",
        "print(bn.shape)\n",
        "l3=np.full((307936,1),2)\n",
        "bb = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_baseball.npy\"))\n",
        "print(bb.shape)\n",
        "l4=np.full((135375,1),3)\n",
        "bird = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_bird.npy\"))\n",
        "print(bird.shape)\n",
        "l5=np.full((133572,1),4)\n",
        "bk = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_bucket.npy\"))\n",
        "print(bk.shape)\n",
        "l6=np.full((124064,1),5)\n",
        "bfly = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_butterfly.npy\"))\n",
        "print(bfly.shape)\n",
        "l7=np.full((117999,1),6)\n",
        "cat = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_cat.npy\"))\n",
        "print(cat.shape)\n",
        "l8=np.full((123202,1),7)\n",
        "cc = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_coffee cup.npy\"))\n",
        "print(cc.shape)\n",
        "l9=np.full((183432,1),8)\n",
        "dolp = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_dolphin.npy\"))\n",
        "print(dolp.shape)\n",
        "l10=np.full((121613,1),9)\n",
        "dn = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_donut.npy\"))\n",
        "print(dn.shape)\n",
        "l11=np.full((140751,1),10)\n",
        "dk = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_duck.npy\"))\n",
        "print(dk.shape)\n",
        "l12=np.full((135480,1),11)\n",
        "fish = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_fish.npy\"))\n",
        "print(fish.shape)\n",
        "l13=np.full((134150,1),12)\n",
        "lf = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_leaf.npy\"))\n",
        "print(lf.shape)\n",
        "l14=np.full((125571,1),13)\n",
        "mt = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_mountain.npy\"))\n",
        "print(mt.shape)\n",
        "l15=np.full((128540,1),14)\n",
        "pn = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_pencil.npy\"))\n",
        "print(pn.shape)\n",
        "l16=np.full((122001,1),15)\n",
        "sf = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_smiley face.npy\"))\n",
        "print(sf.shape)\n",
        "l17=np.full((124386,1),16)\n",
        "snk = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_snake.npy\"))\n",
        "print(snk.shape)\n",
        "l18=np.full((122273,1),17)\n",
        "umb = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_umbrella.npy\"))\n",
        "print(umb.shape)\n",
        "l19=np.full((124084,1),18)\n",
        "wb = torch.from_numpy(np.load(\"/content/full_numpy_bitmap_wine bottle.npy\"))\n",
        "print(wb.shape)\n",
        "l20=np.full((126373,1),19)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19x2S5Fd6A8k",
        "outputId": "fdec6c21-51da-4737-8f53-290a2fb5fcdf"
      },
      "source": [
        "dataset = torch.cat((Ap,ant,bn,bb,bird,bk,bfly,cat,cc,dolp,dn,dk,fish,lf,mt,pn,sf,snk,umb,wb),0)\n",
        "print(dataset.size())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2807037, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3dyN6hpR3gD"
      },
      "source": [
        "labels_set = np.concatenate((l1,l2,l3,l4,l5,l6,l7,l8,l9,l10,l11,l12,l13,l14,l15,l16,l17,l18,l19,l20))\n",
        "# print(np.sum(labels_set))\n",
        "labels_set = torch.from_numpy(labels_set)\n",
        "print(labels_set.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JBS3WXlEtLo",
        "outputId": "00d35efd-37c9-44df-f613-2f6eb496f1ec"
      },
      "source": [
        "train_set, test_set, lbl_train,lbl_test = train_test_split(dataset,labels_set, test_size=0.33, random_state=1)\n",
        "print(train_set.shape)\n",
        "print(test_set.shape)\n",
        "print(lbl_train.shape)\n",
        "print(lbl_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1880714, 784])\n",
            "torch.Size([926323, 784])\n",
            "torch.Size([1880714, 1])\n",
            "torch.Size([926323, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "g9_UvmygWVVL",
        "outputId": "90985016-fbd2-4a1b-e411-8c1c2d7b5262"
      },
      "source": [
        "n = rd.randrange(0,1880713)\n",
        "image,label = train_set[n], lbl_train[n]\n",
        "# print(image.shape)\n",
        "plt.imshow(image.reshape(28,28) , cmap='gray', interpolation = \"nearest\")\n",
        "print(\"Looks like: \"+classes[label])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks like: mountain\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAM9klEQVR4nO3dXaxV9ZnH8d9vEKIBksEhJYSXodMYL2yMnRCjkUw6GWkYvQC8IMVoqDPxVDM0GC+E0ItqJiTVTPHCixoaFUartYoKacyAElJ7VT0SB/GFqgSteAQVm7ExygDPXJxF54hn/fdhv60Nz/eTnOy917PXXk9W+LHe9l5/R4QAnPv+qukGAPQHYQeSIOxAEoQdSIKwA0mc18+F2ebUP9BjEeHxpne0Zbe9xPZ+22/bXtfJZwHoLbd7nd32JEl/kLRY0vuSXpK0MiJeL8zDlh3osV5s2S+X9HZEHIiIY5J+JWlpB58HoIc6CfscSX8c8/r9atpX2B6yPWx7uINlAehQz0/QRcQmSZskduOBJnWyZT8kad6Y13OraQAGUCdhf0nSRba/aXuKpO9L2t6dtgB0W9u78RFx3PZqSTskTZL0YES81rXOAHRV25fe2loYx+xAz/XkSzUAzh6EHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSTaHp9dkmwflPSZpBOSjkfEwm40BaD7Ogp75R8j4uMufA6AHmI3Hkii07CHpJ22X7Y9NN4bbA/ZHrY93OGyAHTAEdH+zPaciDhk+xuSnpP0o4h4ofD+9hcGYEIiwuNN72jLHhGHqscjkp6WdHknnwegd9oOu+2ptqefei7pe5L2dasxAN3Vydn4WZKetn3qcx6NiP/qSlcAuq6jY/YzXhjH7EDP9eSYHcDZg7ADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSS6ccNJnMOmT59erN91113F+nXXXVdb++KLL4rzLlu2rFh/8803i3V8FVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCu8ue4yZPnlysX3nllcX6Qw89VKzPmzevWH/yySdra4sWLSrOe8EFFxTr1157bbH+4osvFuvnKu4uCyRH2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ39LLB8+fJi/cYbb6ytLV68uDjvtGnTivX9+/cX6zfccEOxPjw8XFubP39+cd4dO3YU63Pnzi3WS+vt+eefL857Nmv7OrvtB20fsb1vzLQLbT9n+63qcUY3mwXQfRPZjd8saclp09ZJ2hURF0naVb0GMMBahj0iXpB09LTJSyVtqZ5vkVS+fxCAxrV7D7pZETFSPf9Q0qy6N9oekjTU5nIAdEnHN5yMiCideIuITZI2SZygA5rU7qW3w7ZnS1L1eKR7LQHohXbDvl3Squr5KknbutMOgF5peZ3d9mOSvitppqTDkn4i6RlJv5Y0X9K7klZExOkn8cb7LHbjx7FmzZpi/d577y3W33nnndra7t27i/N+8MEHxfo999xTrH/++efFeidmzpxZrD/77LPF+qWXXlpbK303QZKeeOKJYn2Q1V1nb3nMHhEra0r/1FFHAPqKr8sCSRB2IAnCDiRB2IEkCDuQBD9x7YPbbrutWN+4cWOx/vjjjxfrpctIx48fL857Nps6dWqxvnXr1tra1VdfXZx39erVxfr9999frDeJW0kDyRF2IAnCDiRB2IEkCDuQBGEHkiDsQBJcZ++CJq+jS+f2tfROTJkypbb28MMPF+ddsWJFsX733XcX6+vWNXcPVq6zA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EASHY8Ik0XpWjrX0QfTsWPHamvXX399cd5PP/20WF+7dm2x3uq39qXbh588ebI4b7vYsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEmmus0+aNKlY37BhQ7F+xx131NYeeeSR4rw33XRTsX7ixIliHd3Xap3feuutxfonn3xSrK9fv75YP//882trN998c3HedrXcstt+0PYR2/vGTLvT9iHbr1R/1/SkOwBdM5Hd+M2Slowz/d6IuKz6e7a7bQHotpZhj4gXJB3tQy8AeqiTE3Srbe+tdvNn1L3J9pDtYdvDHSwLQIfaDfvPJX1L0mWSRiT9rO6NEbEpIhZGxMI2lwWgC9oKe0QcjogTEXFS0i8kXd7dtgB0W1thtz17zMvlkvbVvRfAYGh533jbj0n6rqSZkg5L+kn1+jJJIemgpB9GxEjLhfXwvvEzZtSeNpAkPfroo8X6kiXjXXD4f6XfrJeuwUtcR8/ovvvuK9ZvueWW2tq0adOK83755ZfFet1941t+qSYiVo4z+YFW8wEYLHxdFkiCsANJEHYgCcIOJEHYgSTOqp+4XnzxxbW1Z555pjjvggULivVWP0PdvHlzsQ6MtWvXrmJ99erVtbXSv3NJ2rt3b1s9sWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQG6jr7FVdcUazv3LmzttZqiN2rrrqqWN+zZ0+xDpyJffvav8XDJZdcUqxznR1AEWEHkiDsQBKEHUiCsANJEHYgCcIOJDFQ19nPO6/czrZt22prt99+e3Hejz76qK2egHYcOHCgWH/vvfdqa62GF28XW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSKLlkM1dXVgPh2wGMKpuyOaWW3bb82zvtv267ddsr6mmX2j7OdtvVY/lAdIBNKrllt32bEmzI2KP7emSXpa0TNIPJB2NiJ/aXidpRkSsbfFZbNmBHmt7yx4RIxGxp3r+maQ3JM2RtFTSluptWzT6HwCAAXVG3423vUDSdyT9XtKsiBipSh9KmlUzz5CkofZbBNANEz5BZ3uapN9K2hART9n+U0T89Zj6pxFRPG5nNx7ovbZ34yXJ9mRJWyX9MiKeqiYfro7nTx3XH+lGowB6YyJn4y3pAUlvRMTGMaXtklZVz1dJqv/9KYDGTeRs/CJJv5P0qqST1eT1Gj1u/7Wk+ZLelbQiIo62+Cx244Eeq9uN50s1wDmmo2N2AGc/wg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5KYyPjs82zvtv267ddsr6mm32n7kO1Xqr9ret8ugHZNZHz22ZJmR8Qe29MlvSxpmaQVkv4cEf8x4YUxZDPQc3VDNp83gRlHJI1Uzz+z/YakOd1tD0CvndExu+0Fkr4j6ffVpNW299p+0PaMmnmGbA/bHu6oUwAdabkb/5c32tMk/VbShoh4yvYsSR9LCkn/rtFd/X9p8RnsxgM9VrcbP6Gw254s6TeSdkTExnHqCyT9JiK+3eJzCDvQY3Vhn8jZeEt6QNIbY4Nenbg7ZbmkfZ02CaB3JnI2fpGk30l6VdLJavJ6SSslXabR3fiDkn5YncwrfRZbdqDHOtqN7xbCDvRe27vxAM4NhB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSRa3nCyyz6W9O6Y1zOraYNoUHsb1L4kemtXN3v727pCX3/P/rWF28MRsbCxBgoGtbdB7Uuit3b1qzd244EkCDuQRNNh39Tw8ksGtbdB7Uuit3b1pbdGj9kB9E/TW3YAfULYgSQaCbvtJbb3237b9romeqhj+6DtV6thqBsdn64aQ++I7X1jpl1o+znbb1WP446x11BvAzGMd2GY8UbXXdPDn/f9mN32JEl/kLRY0vuSXpK0MiJe72sjNWwflLQwIhr/Aobtf5D0Z0n/eWpoLdv3SDoaET+t/qOcERFrB6S3O3WGw3j3qLe6YcZ/oAbXXTeHP29HE1v2yyW9HREHIuKYpF9JWtpAHwMvIl6QdPS0yUslbameb9HoP5a+q+ltIETESETsqZ5/JunUMOONrrtCX33RRNjnSPrjmNfva7DGew9JO22/bHuo6WbGMWvMMFsfSprVZDPjaDmMdz+dNsz4wKy7doY/7xQn6L5uUUT8vaR/lvRv1e7qQIrRY7BBunb6c0nf0ugYgCOSftZkM9Uw41sl3RYR/zO21uS6G6evvqy3JsJ+SNK8Ma/nVtMGQkQcqh6PSHpao4cdg+TwqRF0q8cjDffzFxFxOCJORMRJSb9Qg+uuGmZ8q6RfRsRT1eTG1914ffVrvTUR9pckXWT7m7anSPq+pO0N9PE1tqdWJ05ke6qk72nwhqLeLmlV9XyVpG0N9vIVgzKMd90w42p43TU+/HlE9P1P0jUaPSP/jqQfN9FDTV9/J+m/q7/Xmu5N0mMa3a37X42e2/hXSX8jaZektyQ9L+nCAertYY0O7b1Xo8Ga3VBvizS6i75X0ivV3zVNr7tCX31Zb3xdFkiCE3RAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kMT/ATL4RNU7b6HYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT0ewQ4AwXxA"
      },
      "source": [
        "class Data_Set(Dataset):\n",
        "    def __init__(self,t_set,lbl_set):\n",
        "        self.x = t_set.reshape(t_set.shape[0],1,28,28)\n",
        "        self.y = lbl_set\n",
        "        self.l = t_set.shape[0]\n",
        "    def __getitem__(self,i):\n",
        "        return self.x[i],self.y[i]\n",
        "    def __len__(self):\n",
        "        return self.l"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UgBroCgzCSo"
      },
      "source": [
        "data_train = Data_Set(train_set,lbl_train)\n",
        "dataloader_train = DataLoader(data_train, batch_size=512, shuffle=False, num_workers=2)\n",
        "data_test = Data_Set(test_set,lbl_test)\n",
        "dataloader_test = DataLoader(data_test, batch_size=512, shuffle=False, num_workers=2)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INajWmImVifh"
      },
      "source": [
        "class ConvNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNetwork, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(1, 8, 5)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(8, 20, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(20 * 4 * 4, 200)\n",
        "        self.fc2 = nn.Linear(200, 120)\n",
        "        self.fc3 = nn.Linear(120, 84)\n",
        "        self.fc4 = nn.Linear(84, 20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u0ZisF-0HTD"
      },
      "source": [
        "def prediction(out,y):\n",
        "    _, predict = torch.max(out,1)\n",
        "    return (predict==y).sum().item()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31o2souJzbiQ"
      },
      "source": [
        "def training(train_loader,model, loss,opt, print_cost):\n",
        "\n",
        "    train_correct=0\n",
        "    train_size = len(train_loader.dataset)\n",
        "    \n",
        "    n_samples = 0\n",
        "    \n",
        "    for i, (imgs,labels) in enumerate(train_loader):\n",
        "\n",
        "        batch_size = train_loader.batch_size\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        labels = labels.squeeze(1) \n",
        "\n",
        "        #forward pass\n",
        "        out = model(imgs.float())\n",
        "        cost = loss(out,labels)\n",
        "        costs.append(cost)\n",
        "        #backward pass\n",
        "        opt.zero_grad()\n",
        "        cost.backward()\n",
        "        opt.step()\n",
        "\n",
        "        #prediction\n",
        "        n_samples += labels.shape[0]\n",
        "        train_correct += prediction(out,labels)\n",
        "        \n",
        "        if (i+1)%100==0 and print_cost:\n",
        "            print(f\"Cost  [{i+1}/{len(train_loader)}] : {cost.item()}\")\n",
        "    if print_cost:\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations ')\n",
        "        plt.title(\"Learning rate =\" + str(alpha))\n",
        "        plt.show()\n",
        "        print(\"---\")\n",
        "    acc= 100*train_correct/n_samples\n",
        "    print(\"Train Accuracy: \",acc,\" %\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_s-FuLs0SQp"
      },
      "source": [
        "def testing(test_loader,model,loss,opt):\n",
        "\n",
        "    test_loss, test_correct = 0, 0\n",
        "    test_cost=[]\n",
        "    num_batches = len(test_loader)\n",
        "    batch_size = test_loader.batch_size\n",
        "\n",
        "    n_samples = 0\n",
        "    i=0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in test_loader:\n",
        "\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            labels = labels.squeeze(1)\n",
        "\n",
        "            # forward pass\n",
        "            out = model(imgs.float())\n",
        "\n",
        "            n_samples += labels.shape[0]\n",
        "            test_loss = loss(out, labels).item()\n",
        "            test_correct += prediction(out,labels)\n",
        "\n",
        "            test_cost.append(test_loss)\n",
        "            i+=1\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    acc = 100*test_correct/n_samples\n",
        "    # print(\"Average Test Loss: \",test_loss)\n",
        "    print(\"Test Accuracy: \",acc,\" %\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLacOvZU0mxh"
      },
      "source": [
        "cnn_model = ConvNetwork().to(device)\n",
        "params = cnn_model.parameters()\n",
        "alpha = 0.001\n",
        "costs=[]\n",
        "epoch_cost = []"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYBSPJNxErbZ"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(params, lr=alpha, betas=(0.9, 0.999), eps=1e-08)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj1fd3cH0uVA"
      },
      "source": [
        "num_epochs=75\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    training(dataloader_train, cnn_model, loss, opt, print_cost=False)\n",
        "    epoch_cost.append(costs[-1])\n",
        "    testing(dataloader_test, cnn_model, loss, opt)        \n",
        "    print(\"---\")\n",
        "\n",
        "#plot cost per epoch graph    \n",
        "plt.plot(np.squeeze(epoch_cost))\n",
        "plt.ylabel('cost')\n",
        "plt.xlabel('epochs ')\n",
        "plt.title(\"Learning rate =\" + str(alpha))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKGwPPsw0FXN"
      },
      "source": [
        "from google.colab import files\n",
        "import helper"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrscRY2cAeVo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7c1b978b-6605-45f8-bccb-b4f026ecf22d"
      },
      "source": [
        "# save the model\n",
        "FILE = 'doodle_model.pth'\n",
        "torch.save(cnn_model.state_dict(), FILE)\n",
        "files.download('doodle_model.pth')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_48d95fb5-bc8f-4ab0-9a20-ac8a142f5889\", \"doodle_model.pth\", 421121)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPaF3gPzB85Y",
        "outputId": "48366737-13c6-4a38-a49a-12f194d5c991"
      },
      "source": [
        "loaded_model = ConvNetwork()\n",
        "loaded_model.load_state_dict(torch.load(FILE))\n",
        "loaded_model.eval()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNetwork(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(8, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=320, out_features=200, bias=True)\n",
              "  (fc2): Linear(in_features=200, out_features=120, bias=True)\n",
              "  (fc3): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc4): Linear(in_features=84, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FI9kwnwmrjSx",
        "outputId": "d2098949-c152-4653-d76b-3e74306e2abd"
      },
      "source": [
        "# test your model's accuracy with predicted results\n",
        "sample = next(iter(dataloader_test))\n",
        "images, labels = sample\n",
        "\n",
        "n = rd.randrange(0,len(images))\n",
        "img = images[n]\n",
        "\n",
        "plt.imshow(img.reshape(28,28),cmap = 'gray')\n",
        "img = img.to(device)\n",
        "img = img.reshape(1,1,28,28)\n",
        "out = cnn_model(img.float())\n",
        "_, predicted = torch.max(out, 1)\n",
        "print(\"Looks like : \",classes[predicted])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looks like :  cat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}